{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "from utils import score, create_submission\n",
    "\n",
    "def train(df: pd.DataFrame):\n",
    "    target = 'total_fire_size'\n",
    "    features = features = [col for col in df.columns if col != target]\n",
    "\n",
    "    # Sort by time to ensure valid time-series splits\n",
    "    df = df.sort_values(\"month\")\n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "    \n",
    "    def custom_cv_metric(estimator, X_cv, y_cv):\n",
    "        \"\"\"\n",
    "        Implements the metric:\n",
    "            mean( min( |log(y_pred / y_true)|, 10 ) )\n",
    "        and returns its negative for hyperparameter tuning.\n",
    "        \"\"\"        \n",
    "        y_pred = estimator.predict(X_cv)\n",
    "        eps = 1e-15\n",
    "        y_pred = np.maximum(y_pred, eps)\n",
    "        y_true = np.maximum(y_cv, eps)\n",
    "        \n",
    "        log_errors = np.abs(np.log(y_pred / y_true))\n",
    "        log_errors_clamped = np.minimum(log_errors, 10.0)\n",
    "        score_value = np.mean(log_errors_clamped)\n",
    "        return -score_value\n",
    "    \n",
    "    def squared_log_error_obj(preds, dtrain):\n",
    "        \"\"\"\n",
    "        Custom objective function for squared error in log-space:\n",
    "        L = (log(pred) - log(label))^2\n",
    "        \"\"\"\n",
    "        labels = dtrain.get_label()\n",
    "        eps = 1e-15\n",
    "\n",
    "        preds = np.maximum(preds, eps)\n",
    "        diff = np.log(preds) - np.log(labels)\n",
    "        grad = 2.0 * diff / preds\n",
    "        hess = 2.0 * (1.0 - diff) / (preds ** 2)\n",
    "        return grad, hess\n",
    "\n",
    "    \n",
    "    # Define the parameter search space using skopt spaces.\n",
    "    param_space = {\n",
    "        'max_depth': Integer(3, 6),\n",
    "        'learning_rate': Real(0.01, 0.2, prior='log-uniform'),\n",
    "        'subsample': Real(0.7, 1.0),\n",
    "        'colsample_bytree': Real(0.7, 1.0),\n",
    "        'n_estimators': Integer(50, 300)\n",
    "    }\n",
    "    \n",
    "    # Use TimeSeriesSplit to respect time order and avoid leakage.\n",
    "    cv = TimeSeriesSplit(n_splits=5)\n",
    "    \n",
    "    # Initialize the XGBoost regressor (scikit-learn API).\n",
    "    model = XGBRegressor(\n",
    "        objective=squared_log_error_obj,\n",
    "        eval_metric='rmse',\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Set up Bayesian optimization with BayesSearchCV.\n",
    "    bayes_search = BayesSearchCV(\n",
    "        estimator=model,\n",
    "        search_spaces=param_space,\n",
    "        n_iter=20,\n",
    "        scoring=custom_cv_metric,\n",
    "        cv=cv,\n",
    "        verbose=1,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Run the Bayesian search.\n",
    "    bayes_search.fit(X, y)\n",
    "    \n",
    "    print(\"Best parameters found:\", bayes_search.best_params_)\n",
    "    # Our scorer returns negative custom score, so we multiply by -1.\n",
    "    print(\"Best CV custom score:\", -bayes_search.best_score_)\n",
    "    \n",
    "    # Retrieve the best estimator.\n",
    "    best_model = bayes_search.best_estimator_\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_log_clamped_score(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Implements: mean( min( |log(y_pred / y_true)|, 10 ) )\n",
    "    \"\"\"\n",
    "    eps = 1e-15\n",
    "    y_pred = np.maximum(y_pred, eps)\n",
    "    y_true = np.maximum(y_true, eps)\n",
    "    \n",
    "    log_errors = np.abs(np.log(y_pred / y_true))\n",
    "    log_errors_clamped = np.minimum(log_errors, 10.0)\n",
    "    return np.mean(log_errors_clamped)\n",
    "\n",
    "def evaluate_train_test_scores(df, best_model):\n",
    "    \"\"\"\n",
    "    Perform manual time-series CV with the best-found model to compute\n",
    "    separate train/test scores for each fold.\n",
    "    \"\"\"\n",
    "    target = 'total_fire_size'\n",
    "    features = [col for col in df.columns if col != target]\n",
    "\n",
    "    # Sort for time-based CV\n",
    "    df = df.sort_values(\"month\")\n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "    \n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    \n",
    "    train_scores, test_scores = [], []\n",
    "    for train_idx, test_idx in tscv.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        \n",
    "        # Re-initialize a new model with the same parameters\n",
    "        # (Alternatively, you can use sklearn.base.clone(best_model))\n",
    "        model_fold = XGBRegressor(**best_model.get_params())\n",
    "        model_fold.fit(X_train, y_train)\n",
    "        \n",
    "        # Predictions\n",
    "        y_train_pred = model_fold.predict(X_train)\n",
    "        y_test_pred = model_fold.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        fold_train_score = calc_log_clamped_score(y_train, y_train_pred)\n",
    "        fold_test_score  = calc_log_clamped_score(y_test, y_test_pred)\n",
    "        \n",
    "        train_scores.append(fold_train_score)\n",
    "        test_scores.append(fold_test_score)\n",
    "    \n",
    "    # Print or return the results\n",
    "    print(\"Train scores (each fold):\", train_scores)\n",
    "    print(\"Test scores (each fold): \", test_scores)\n",
    "    print(\"Mean train score:\", np.mean(train_scores))\n",
    "    print(\"Mean test score: \", np.mean(test_scores))\n",
    "    \n",
    "    return train_scores, test_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    df = ...\n",
    "    best_model = train(df)\n",
    "    train_scores, test_scores = evaluate_train_test_scores(df, best_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
