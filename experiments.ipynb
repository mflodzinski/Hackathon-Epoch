{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-22T12:32:08.890516Z",
     "start_time": "2025-02-22T12:32:08.507365Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import TargetEncoder\n",
    "\n",
    "dataset = pd.read_csv('datasets/dataset_cleaned.csv')\n",
    "# dataset = pd.get_dummies(dataset, columns=['STATE'], dtype=int)\n",
    "# dataset.head()\n",
    "\n",
    "dataset['STATE'] = TargetEncoder(smooth='auto').fit_transform(pd.DataFrame(dataset['STATE']),   dataset['TOTAL_FIRE_SIZE'])\n",
    "\n",
    "X = dataset.drop('TOTAL_FIRE_SIZE', axis=1)\n",
    "y = dataset['TOTAL_FIRE_SIZE']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the XGBoost classifier\n",
    "model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "def calc_log_clamped_score(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Implements: mean( min( |log(y_pred / y_true)|, 10 ) )\n",
    "    \"\"\"\n",
    "    eps = 1e-15\n",
    "    y_pred = np.maximum(y_pred, eps)\n",
    "    y_true = np.maximum(y_true, eps)\n",
    "\n",
    "    log_errors = np.abs(np.log(y_pred / y_true))\n",
    "    log_errors_clamped = np.minimum(log_errors, 10.0)\n",
    "    return np.mean(log_errors_clamped)\n",
    "\n",
    "\n",
    "# Make predictions and calculate mean squared error\n",
    "y_pred = model.predict(X_test)\n",
    "score = calc_log_clamped_score(y_test, y_pred)\n",
    "print(\"Score:\", score)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 3.811559011023252\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T12:42:10.886970Z",
     "start_time": "2025-02-22T12:42:09.309115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import TargetEncoder\n",
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_csv('datasets/dataset_cleaned.csv')\n",
    "\n",
    "# Encode 'STATE' using a target encoder\n",
    "encoder = TargetEncoder()\n",
    "dataset['STATE'] = encoder.fit_transform(dataset['STATE'], dataset['TOTAL_FIRE_SIZE'])\n",
    "\n",
    "# Prepare features and target\n",
    "X = dataset.drop('TOTAL_FIRE_SIZE', axis=1).values\n",
    "y = dataset['TOTAL_FIRE_SIZE'].values\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define the custom loss function\n",
    "def custom_loss(y_true, y_pred):\n",
    "    eps = 1e-15\n",
    "    y_pred = tf.maximum(y_pred, eps)\n",
    "    y_true = tf.maximum(y_true, eps)\n",
    "    log_errors = tf.abs(tf.math.log(y_pred / y_true))\n",
    "    log_errors_clamped = tf.minimum(log_errors, 10.0)\n",
    "    return tf.reduce_mean(log_errors_clamped)\n",
    "\n",
    "# Build a simple neural network model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)  # Linear activation by default for regression\n",
    "])\n",
    "\n",
    "# Compile the model with the custom loss\n",
    "model.compile(optimizer='adam', loss=custom_loss)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test).flatten()\n",
    "\n",
    "# Calculate the custom score using numpy (for verification)\n",
    "def calc_log_clamped_score_np(y_true, y_pred):\n",
    "    eps = 1e-15\n",
    "    y_pred = np.maximum(y_pred, eps)\n",
    "    y_true = np.maximum(y_true, eps)\n",
    "    log_errors = np.abs(np.log(y_pred / y_true))\n",
    "    log_errors_clamped = np.minimum(log_errors, 10.0)\n",
    "    return np.mean(log_errors_clamped)\n",
    "\n",
    "score = calc_log_clamped_score_np(y_test, y_pred)\n",
    "print(\"Score:\", score)"
   ],
   "id": "569150c3fcff5e8c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-22 13:42:09.451060: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-22 13:42:09.451716: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-02-22 13:42:09.454068: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-02-22 13:42:09.459625: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1740228129.468717  706813 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1740228129.471419  706813 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-22 13:42:09.482221: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected a 2-dimensional container but got <class 'pandas.core.series.Series'> instead. Pass a DataFrame containing a single row (i.e. single sample) or a single column (i.e. single feature) instead.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 14\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m# Encode 'STATE' using a target encoder\u001B[39;00m\n\u001B[1;32m     13\u001B[0m encoder \u001B[38;5;241m=\u001B[39m TargetEncoder()\n\u001B[0;32m---> 14\u001B[0m dataset[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSTATE\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mencoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mSTATE\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mTOTAL_FIRE_SIZE\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;66;03m# Prepare features and target\u001B[39;00m\n\u001B[1;32m     17\u001B[0m X \u001B[38;5;241m=\u001B[39m dataset\u001B[38;5;241m.\u001B[39mdrop(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTOTAL_FIRE_SIZE\u001B[39m\u001B[38;5;124m'\u001B[39m, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mvalues\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_set_output.py:319\u001B[0m, in \u001B[0;36m_wrap_method_output.<locals>.wrapped\u001B[0;34m(self, X, *args, **kwargs)\u001B[0m\n\u001B[1;32m    317\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(f)\n\u001B[1;32m    318\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 319\u001B[0m     data_to_wrap \u001B[38;5;241m=\u001B[39m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    320\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_to_wrap, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[1;32m    321\u001B[0m         \u001B[38;5;66;03m# only wrap the first output for cross decomposition\u001B[39;00m\n\u001B[1;32m    322\u001B[0m         return_tuple \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    323\u001B[0m             _wrap_data_with_container(method, data_to_wrap[\u001B[38;5;241m0\u001B[39m], X, \u001B[38;5;28mself\u001B[39m),\n\u001B[1;32m    324\u001B[0m             \u001B[38;5;241m*\u001B[39mdata_to_wrap[\u001B[38;5;241m1\u001B[39m:],\n\u001B[1;32m    325\u001B[0m         )\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1389\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1382\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m   1384\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m   1385\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1386\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m   1387\u001B[0m     )\n\u001B[1;32m   1388\u001B[0m ):\n\u001B[0;32m-> 1389\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/sklearn/preprocessing/_target_encoder.py:259\u001B[0m, in \u001B[0;36mTargetEncoder.fit_transform\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m    236\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Fit :class:`TargetEncoder` and transform X with the target encoding.\u001B[39;00m\n\u001B[1;32m    237\u001B[0m \n\u001B[1;32m    238\u001B[0m \u001B[38;5;124;03m.. note::\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    255\u001B[0m \u001B[38;5;124;03m    Transformed input.\u001B[39;00m\n\u001B[1;32m    256\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    257\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel_selection\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m KFold, StratifiedKFold  \u001B[38;5;66;03m# avoid circular import\u001B[39;00m\n\u001B[0;32m--> 259\u001B[0m X_ordinal, X_known_mask, y_encoded, n_categories \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_encodings_all\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    261\u001B[0m \u001B[38;5;66;03m# The cv splitter is voluntarily restricted to *KFold to enforce non\u001B[39;00m\n\u001B[1;32m    262\u001B[0m \u001B[38;5;66;03m# overlapping validation folds, otherwise the fit_transform output will\u001B[39;00m\n\u001B[1;32m    263\u001B[0m \u001B[38;5;66;03m# not be well-specified.\u001B[39;00m\n\u001B[1;32m    264\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_type_ \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontinuous\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/sklearn/preprocessing/_target_encoder.py:359\u001B[0m, in \u001B[0;36mTargetEncoder._fit_encodings_all\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m    353\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpreprocessing\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m    354\u001B[0m     LabelBinarizer,\n\u001B[1;32m    355\u001B[0m     LabelEncoder,\n\u001B[1;32m    356\u001B[0m )\n\u001B[1;32m    358\u001B[0m check_consistent_length(X, y)\n\u001B[0;32m--> 359\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhandle_unknown\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mignore\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mensure_all_finite\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mallow-nan\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    361\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mauto\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    362\u001B[0m     accepted_target_types \u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulticlass\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontinuous\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:83\u001B[0m, in \u001B[0;36m_BaseEncoder._fit\u001B[0;34m(self, X, handle_unknown, ensure_all_finite, return_counts, return_and_ignore_missing_for_infrequent)\u001B[0m\n\u001B[1;32m     81\u001B[0m _check_n_features(\u001B[38;5;28mself\u001B[39m, X, reset\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     82\u001B[0m _check_feature_names(\u001B[38;5;28mself\u001B[39m, X, reset\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m---> 83\u001B[0m X_list, n_samples, n_features \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_X\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     84\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mensure_all_finite\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_all_finite\u001B[49m\n\u001B[1;32m     85\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     86\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_features_in_ \u001B[38;5;241m=\u001B[39m n_features\n\u001B[1;32m     88\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcategories \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mauto\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:49\u001B[0m, in \u001B[0;36m_BaseEncoder._check_X\u001B[0;34m(self, X, ensure_all_finite)\u001B[0m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;124;03mPerform custom check_array:\u001B[39;00m\n\u001B[1;32m     38\u001B[0m \u001B[38;5;124;03m- convert list of strings to object dtype\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     45\u001B[0m \n\u001B[1;32m     46\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mhasattr\u001B[39m(X, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124miloc\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(X, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mndim\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m0\u001B[39m) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m):\n\u001B[1;32m     48\u001B[0m     \u001B[38;5;66;03m# if not a dataframe, do normal check_array validation\u001B[39;00m\n\u001B[0;32m---> 49\u001B[0m     X_temp \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mensure_all_finite\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_all_finite\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(X, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m np\u001B[38;5;241m.\u001B[39missubdtype(X_temp\u001B[38;5;241m.\u001B[39mdtype, np\u001B[38;5;241m.\u001B[39mstr_):\n\u001B[1;32m     51\u001B[0m         X \u001B[38;5;241m=\u001B[39m check_array(X, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mobject\u001B[39m, ensure_all_finite\u001B[38;5;241m=\u001B[39mensure_all_finite)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:1093\u001B[0m, in \u001B[0;36mcheck_array\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[1;32m   1086\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1087\u001B[0m             msg \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m   1088\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpected 2D array, got 1D array instead:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124marray=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00marray\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1089\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1090\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myour data has a single feature or array.reshape(1, -1) \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1091\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mif it contains a single sample.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1092\u001B[0m             )\n\u001B[0;32m-> 1093\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg)\n\u001B[1;32m   1095\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dtype_numeric \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(array\u001B[38;5;241m.\u001B[39mdtype, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkind\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m array\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mkind \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUSV\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m   1096\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1097\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnumeric\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m is not compatible with arrays of bytes/strings.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1098\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConvert your data to numeric values explicitly instead.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1099\u001B[0m     )\n",
      "\u001B[0;31mValueError\u001B[0m: Expected a 2-dimensional container but got <class 'pandas.core.series.Series'> instead. Pass a DataFrame containing a single row (i.e. single sample) or a single column (i.e. single feature) instead."
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
